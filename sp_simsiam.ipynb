{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from RandomCompositeTransformation import RandomCompositeTransformation as CompositeAugmenter\n",
    "import time\n",
    "import random\n",
    "from textattack.augmentation import Augmenter\n",
    "from textattack.transformations import WordSwapWordNet, WordSwapEmbedding, BackTranslation, WordSwapExtend, WordSwapRandomCharacterSubstitution, WordSwapHomoglyphSwap, WordSwapRandomCharacterInsertion\n",
    "from textattack.constraints.pre_transformation import RepeatModification, StopwordModification\n",
    "from textattack.constraints.semantics import WordEmbeddingDistance\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \"\"\"Dataset for loading text data with optional augmentation.\"\"\"\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_length=128, augment=False, augmenter=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.augment = augment\n",
    "        self.augmenter = augmenter\n",
    "\n",
    "        if self.augment:\n",
    "            self.text_views1 = []\n",
    "            self.text_views2 = []\n",
    "            for text in self.texts:\n",
    "                # Generate two augmented views for each text\n",
    "                augmented_text1 = self.text_augment(text)\n",
    "\n",
    "                while True:\n",
    "                    augmented_text2 = self.text_augment(text)\n",
    "                    if augmented_text1 != augmented_text2:\n",
    "                        break\n",
    "\n",
    "                self.text_views1.append(augmented_text1)\n",
    "                self.text_views2.append(augmented_text2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "\n",
    "        if self.augment:\n",
    "            text_view1 = self.text_views1[idx]\n",
    "            text_view2 = self.text_views2[idx]\n",
    "        else:\n",
    "            text_view1 = text\n",
    "\n",
    "        inputs1 = self.tokenizer(\n",
    "            text_view1,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs1 = {key: val.squeeze(0) for key, val in inputs1.items()}\n",
    "\n",
    "        if self.augment:\n",
    "            inputs2 = self.tokenizer(\n",
    "                text_view2,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            inputs2 = {key: val.squeeze(0) for key, val in inputs2.items()}\n",
    "            return inputs1, inputs2\n",
    "\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return inputs1, label\n",
    "        return inputs1\n",
    "\n",
    "    def text_augment(self, text):\n",
    "        \"\"\"text augmentation.\"\"\"\n",
    "        augmented_texts = self.augmenter.augment(text)\n",
    "        return random.choice(augmented_texts)\n",
    "\n",
    "class SimSiamText(nn.Module):\n",
    "    def __init__(self, base_encoder, dim=2048, pred_dim=512):\n",
    "        super(SimSiamText, self).__init__()\n",
    "        self.encoder = base_encoder\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(768, dim, bias=False),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(dim, dim, bias=False),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(dim, dim, bias=True),\n",
    "        )\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(dim, pred_dim, bias=False),\n",
    "            nn.BatchNorm1d(pred_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(pred_dim, dim, bias=True),\n",
    "        )\n",
    "        self.regressor = nn.Linear(768, 1)  # 线性回归头\n",
    "\n",
    "    def forward(self, x1, x2, regression=False):\n",
    "        \"\"\"\n",
    "          定义模型的前向传播过程\n",
    "          x1 和 x2 是同一批图像的两个不同增强视图。\n",
    "          z1 和 z2 是编码器对 x1 和 x2 的编码结果。\n",
    "          p1 和 p2 是预测器对 z1 和 z2 的预测结果。\n",
    "        \"\"\"\n",
    "        if regression:\n",
    "            return self.regressor(self.encoder(x1)[\"pooler_output\"])  # 仅用于回归\n",
    "        z1 = self.projector(self.encoder(x1)[\"pooler_output\"])\n",
    "        z2 = self.projector(self.encoder(x2)[\"pooler_output\"])\n",
    "        p1 = self.predictor(z1)\n",
    "        p2 = self.predictor(z2)\n",
    "        # z1.detach() 和 z2.detach() 表示在反向传播时不计算 z1 和 z2 的梯度，因为它们只作为目标使用。\n",
    "        return p1, p2, z1.detach(), z2.detach()\n",
    "    \n",
    "    def remove_projection_head(self):\n",
    "        \"\"\"移除 projector 和 predictor 以用于微调\"\"\"\n",
    "        self.projector = None\n",
    "        self.predictor = None\n",
    "\n",
    "\n",
    "def train_simsiam(model, dataloader, criterion, optimizer, device, print_freq=10):\n",
    "    \"\"\"训练 SimSiam 并打印训练进度和损失\"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(10):  # 预训练 10 轮\n",
    "        epoch_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            inputs1 = {key: val.to(device) for key, val in batch[0].items()}\n",
    "            inputs2 = {key: val.to(device) for key, val in batch[1].items()}\n",
    "\n",
    "            p1, p2, z1, z2 = model(inputs1, inputs2)\n",
    "            loss = -(criterion(p1, z2).mean() + criterion(p2, z1).mean()) * 0.5\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % print_freq == 0:\n",
    "                print(f\"Epoch [{epoch+1}/10], Step [{batch_idx}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1}/10] Completed | Avg Loss: {avg_loss:.4f} | Time: {elapsed_time:.2f}s\\n\")\n",
    "\n",
    "def fine_tune(model, dataloader, criterion, optimizer, device, print_freq=10):\n",
    "    \"\"\"微调 SimSiam 进行回归任务，并打印训练进度和损失\"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(5):  # 微调 5 轮\n",
    "        epoch_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            inputs = {key: val.to(device) for key, val in batch[0].items()}\n",
    "            labels = batch[1].to(device)\n",
    "\n",
    "            preds = model(inputs, regression=True).squeeze()  # 取回归输出\n",
    "            loss = criterion(preds, labels)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % print_freq == 0:\n",
    "                print(f\"Fine-tune Epoch [{epoch+1}/5], Step [{batch_idx}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Fine-tune Epoch [{epoch+1}/5] Completed | Avg Loss: {avg_loss:.4f} | Time: {elapsed_time:.2f}s\\n\")\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"评估模型在测试集上的 MAE 误差\"\"\"\n",
    "    model.eval()\n",
    "    total_mae = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {key: val.to(device) for key, val in batch[0].items()}\n",
    "            labels = batch[1].to(device)\n",
    "\n",
    "            preds = model(inputs, regression=True).squeeze()\n",
    "            mae = torch.abs(preds - labels).sum().item()  # 计算 MAE\n",
    "            total_mae += mae\n",
    "            num_samples += labels.size(0)\n",
    "\n",
    "    avg_mae = total_mae / num_samples\n",
    "    print(f\"Evaluation - MAE: {avg_mae:.4f}\")\n",
    "\n",
    "# 主运行逻辑\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    # 定义不同的增强方法\n",
    "    wordnet_transformation = WordSwapWordNet()\n",
    "    #embedding_transformation = WordSwapEmbedding(max_candidates=5)\n",
    "    backtranslate_transformation = BackTranslation(chained_back_translation=2)\n",
    "    #extendword_transformation = WordSwapExtend()\n",
    "    randomwordsubs_transformation = WordSwapRandomCharacterSubstitution()\n",
    "    homoglyphswap_transformation = WordSwapHomoglyphSwap()\n",
    "    randomcharinsert_transformation = WordSwapRandomCharacterInsertion()\n",
    "\n",
    "    # 组合多个增强方法，并指定执行概率\n",
    "    random_composite_transformation = CompositeAugmenter(\n",
    "        transformations=[\n",
    "            backtranslate_transformation, \n",
    "            homoglyphswap_transformation, \n",
    "            wordnet_transformation, \n",
    "            randomwordsubs_transformation,\n",
    "            randomcharinsert_transformation\n",
    "        ],\n",
    "        probabilities=[1, 0.5, 0.5, 0.1, 0.1]  # 执行概率\n",
    "    )\n",
    "\n",
    "    # 定义约束，避免对停用词进行修改，防止重复修改\n",
    "    constraints = [RepeatModification(), StopwordModification()]\n",
    "\n",
    "    # 语义相似性约束\n",
    "    semantic_constraint = WordEmbeddingDistance(min_cos_sim=0.8)\n",
    "    constraints.append(semantic_constraint)\n",
    "\n",
    "    # 创建增强器\n",
    "    text_augmenter = Augmenter(\n",
    "        transformation=random_composite_transformation,\n",
    "        constraints=constraints,\n",
    "        pct_words_to_swap=0.1,\n",
    "        transformations_per_example=3  # 生成 3 个不同版本的增强文本\n",
    "    )\n",
    "\n",
    "    # 加载数据\n",
    "    data = pd.read_csv('data/mes_all.csv')\n",
    "    data['text'] = data['title'] + ' ' + data['description']\n",
    "    texts = data['text'].value.to_list()\n",
    "\n",
    "    # 预训练数据集\n",
    "    dataset = TextDataset(texts, tokenizer=tokenizer, augment=True, max_length=512, augmenter=text_augmenter)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # 初始化模型\n",
    "    simsiam = SimSiamText(base_encoder=bert_model).to(device)\n",
    "\n",
    "    # 预训练 SimSiam\n",
    "    criterion = nn.CosineSimilarity(dim=1).to(device)\n",
    "    optimizer = torch.optim.Adam(simsiam.parameters(), lr=3e-4)\n",
    "    train_simsiam(simsiam, dataloader, criterion, optimizer, device)\n",
    "\n",
    "    # **移除 projector 和 predictor**\n",
    "    simsiam.remove_projection_head()\n",
    "\n",
    "    # 划分数据集\n",
    "    labeled_data = data[data['storypoint'] != -1]\n",
    "    split_idx = int(len(labeled_data) * 0.8)\n",
    "\n",
    "    fine_tune_data = labeled_data.iloc[:split_idx]\n",
    "\n",
    "    fine_tune_texts = fine_tune_data['text'].values.to_list()\n",
    "    fine_tune_labels = fine_tune_data['storypoint'].values.to_list()\n",
    "\n",
    "    # 微调（回归任务）\n",
    "    labeled_dataset = TextDataset(fine_tune_texts, fine_tune_labels, tokenizer=tokenizer, augment=False)\n",
    "    labeled_dataloader = DataLoader(labeled_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    regression_criterion = nn.MSELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(simsiam.parameters(), lr=3e-4)\n",
    "    fine_tune(simsiam, labeled_dataloader, regression_criterion, optimizer, device)\n",
    "\n",
    "    test_data = labeled_data.iloc[split_idx:]\n",
    "    test_texts = test_data['text'].values.to_list()\n",
    "    test_labels = test_data['storypoint'].values.to_list()\n",
    "\n",
    "    test_dataset = TextDataset(test_texts, test_labels, tokenizer=tokenizer, augment=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # 评估模型\n",
    "    evaluate(simsiam, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "# 定义不同的增强方法\n",
    "wordnet_transformation = WordSwapWordNet()\n",
    "#embedding_transformation = WordSwapEmbedding(max_candidates=5)\n",
    "backtranslate_transformation = BackTranslation(chained_back_translation=2)\n",
    "#extendword_transformation = WordSwapExtend()\n",
    "randomwordsubs_transformation = WordSwapRandomCharacterSubstitution()\n",
    "homoglyphswap_transformation = WordSwapHomoglyphSwap()\n",
    "randomcharinsert_transformation = WordSwapRandomCharacterInsertion()\n",
    "\n",
    "# 组合多个增强方法，并指定执行概率\n",
    "random_composite_transformation = CompositeAugmenter(\n",
    "    transformations=[\n",
    "        backtranslate_transformation, \n",
    "        homoglyphswap_transformation, \n",
    "        wordnet_transformation, \n",
    "        randomwordsubs_transformation,\n",
    "        randomcharinsert_transformation\n",
    "    ],\n",
    "    probabilities=[1, 0.5, 0.5, 0.1, 0.1]  # 执行概率\n",
    ")\n",
    "\n",
    "# 定义约束，避免对停用词进行修改，防止重复修改\n",
    "constraints = [RepeatModification(), StopwordModification()]\n",
    "\n",
    "# 语义相似性约束\n",
    "semantic_constraint = WordEmbeddingDistance(min_cos_sim=0.8)\n",
    "constraints.append(semantic_constraint)\n",
    "\n",
    "# 创建增强器\n",
    "text_augmenter = Augmenter(\n",
    "    transformation=random_composite_transformation,\n",
    "    constraints=constraints,\n",
    "    pct_words_to_swap=0.1,\n",
    "    transformations_per_example=3  # 生成 3 个不同版本的增强文本\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m texts \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 预训练数据集\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTextDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_augmenter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m, in \u001b[0;36mTextDataset.__init__\u001b[1;34m(self, texts, labels, tokenizer, max_length, augment, augmenter)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_views2 \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtexts:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Generate two augmented views for each text\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     augmented_text1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_augment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m         augmented_text2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_augment(text)\n",
      "Cell \u001b[1;32mIn[7], line 65\u001b[0m, in \u001b[0;36mTextDataset.text_augment\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtext_augment\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"text augmentation.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     augmented_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugmenter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m random\u001b[38;5;241m.\u001b[39mchoice(augmented_texts)\n",
      "File \u001b[1;32mc:\\Users\\henry\\Workspace\\deepcluster\\.venv\\Lib\\site-packages\\textattack\\augmentation\\augmenter.py:126\u001b[0m, in \u001b[0;36mAugmenter.augment\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    123\u001b[0m words_swapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(current_text\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodified_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m words_swapped \u001b[38;5;241m<\u001b[39m num_words_to_swap:\n\u001b[1;32m--> 126\u001b[0m     transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_transformation_constraints\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# Get rid of transformations we already have\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     transformed_texts \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    132\u001b[0m         t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m transformed_texts \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_transformed_texts\n\u001b[0;32m    133\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\henry\\Workspace\\deepcluster\\.venv\\Lib\\site-packages\\textattack\\transformations\\composite_transformation.py:39\u001b[0m, in \u001b[0;36mCompositeTransformation.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m new_attacked_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transformation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformations:\n\u001b[1;32m---> 39\u001b[0m     new_attacked_texts\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mtransformation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(new_attacked_texts)\n",
      "File \u001b[1;32mc:\\Users\\henry\\Workspace\\deepcluster\\.venv\\Lib\\site-packages\\textattack\\transformations\\transformation.py:57\u001b[0m, in \u001b[0;36mTransformation.__call__\u001b[1;34m(self, current_text, pre_transformation_constraints, indices_to_modify, shifted_idxs, return_indices)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_indices:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indices_to_modify\n\u001b[1;32m---> 57\u001b[0m transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_transformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_to_modify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m transformed_texts:\n\u001b[0;32m     59\u001b[0m     text\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_transformation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\henry\\Workspace\\deepcluster\\.venv\\Lib\\site-packages\\textattack\\transformations\\sentence_transformations\\back_translation.py:89\u001b[0m, in \u001b[0;36mBackTranslation._get_transformations\u001b[1;34m(self, current_text, indices_to_modify)\u001b[0m\n\u001b[0;32m     84\u001b[0m list_of_target_lang \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_tokenizer\u001b[38;5;241m.\u001b[39msupported_language_codes,\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchained_back_translation,\n\u001b[0;32m     87\u001b[0m )\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_lang \u001b[38;5;129;01min\u001b[39;00m list_of_target_lang:\n\u001b[1;32m---> 89\u001b[0m     target_language_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_lang\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     src_language_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslate(\n\u001b[0;32m     96\u001b[0m         target_language_text,\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_model,\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_tokenizer,\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_lang,\n\u001b[0;32m    100\u001b[0m     )\n\u001b[0;32m    101\u001b[0m     current_text \u001b[38;5;241m=\u001b[39m src_language_text[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\henry\\Workspace\\deepcluster\\.venv\\Lib\\site-packages\\textattack\\transformations\\sentence_transformations\\back_translation.py:74\u001b[0m, in \u001b[0;36mBackTranslation.translate\u001b[1;34m(self, input, model, tokenizer, lang)\u001b[0m\n\u001b[0;32m     71\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mprepare_seq2seq_batch(src_texts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# translate the input\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m translated \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoded_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m translated_input \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(translated, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m translated_input\n",
      "File \u001b[1;32mc:\\Users\\henry\\Workspace\\deepcluster\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henry\\Workspace\\deepcluster\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2286\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2278\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2279\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2280\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2281\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2282\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2283\u001b[0m     )\n\u001b[0;32m   2285\u001b[0m     \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[1;32m-> 2286\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2292\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2293\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2294\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   2297\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2298\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2299\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2300\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2306\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2307\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\henry\\Workspace\\deepcluster\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3566\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3564\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(next_tokens, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, _indices)\n\u001b[0;32m   3565\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3566\u001b[0m     next_token_scores, next_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_token_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tokens_to_keep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlargest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m   3568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3570\u001b[0m next_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiv(next_tokens, vocab_size, rounding_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3571\u001b[0m next_tokens \u001b[38;5;241m=\u001b[39m next_tokens \u001b[38;5;241m%\u001b[39m vocab_size\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "data = pd.read_csv('data/mes_all.csv')\n",
    "data['text'] = data['title'] + ' ' + data['description']\n",
    "texts = data['text'].values.tolist()\n",
    "\n",
    "# 预训练数据集\n",
    "dataset = TextDataset(texts, tokenizer=tokenizer, augment=True, max_length=512, augmenter=text_augmenter)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "simsiam = SimSiamText(base_encoder=bert_model).to(device)\n",
    "\n",
    "# 预训练 SimSiam\n",
    "criterion = nn.CosineSimilarity(dim=1).to(device)\n",
    "optimizer = torch.optim.Adam(simsiam.parameters(), lr=3e-4)\n",
    "train_simsiam(simsiam, dataloader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除 projector 和 predictor\n",
    "simsiam.remove_projection_head()\n",
    "\n",
    "# 划分数据集\n",
    "labeled_data = data[data['storypoint'] != -1]\n",
    "split_idx = int(len(labeled_data) * 0.8)\n",
    "\n",
    "fine_tune_data = labeled_data.iloc[:split_idx]\n",
    "\n",
    "fine_tune_texts = fine_tune_data['text'].values.to_list()\n",
    "fine_tune_labels = fine_tune_data['storypoint'].values.to_list()\n",
    "\n",
    "# 微调（回归任务）\n",
    "labeled_dataset = TextDataset(fine_tune_texts, fine_tune_labels, tokenizer=tokenizer, augment=False)\n",
    "labeled_dataloader = DataLoader(labeled_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "regression_criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(simsiam.parameters(), lr=3e-4)\n",
    "fine_tune(simsiam, labeled_dataloader, regression_criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = labeled_data.iloc[split_idx:]\n",
    "test_texts = test_data['text'].values.to_list()\n",
    "test_labels = test_data['storypoint'].values.to_list()\n",
    "\n",
    "test_dataset = TextDataset(test_texts, test_labels, tokenizer=tokenizer, augment=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 评估模型\n",
    "evaluate(simsiam, test_dataloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
